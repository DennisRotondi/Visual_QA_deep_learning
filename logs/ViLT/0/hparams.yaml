batch_size: 256
n_cpu: 8
qv_size: 1000
av_size: 1000
lr: 0.0003
wd: 0
word_emb_dim: 300
lstm_hidden_dim: 512
lstm_num_layers: 2
output_dim: 1024
bidirectional: false
dropout: 0.3
trainable_embeddings: true
